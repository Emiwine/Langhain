{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d62f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content=\"Good morning everyone,\\n\\nToday, I want to talk about a fundamental yet powerful concept in the data world — Data Ingestion.\\n\\nData ingestion is the process of collecting and bringing data from various sources into a centralized system, like a data warehouse, data lake, or a database, where it can be further processed, analyzed, or stored.\\n\\nIn today’s digital era, businesses collect data from many sources — mobile apps, websites, IoT devices, social media, and more. But having data in different places is not helpful unless we can bring it all together. That’s exactly what data ingestion does. It acts like a bridge — gathering raw data and transporting it into a system where it becomes usable.\\n\\nThere are two major types of data ingestion: batch and real-time. In batch ingestion, data is collected and loaded at scheduled intervals — like every hour or once a day. This is great for systems that don’t need instant updates. On the other hand, real-time ingestion captures and loads data continuously, almost instantly — perfect for applications like fraud detection, live analytics, or monitoring smart devices.\\n\\nMany modern tools help with data ingestion — such as Apache Kafka for streaming, Apache NiFi for data flows, and cloud services like AWS Glue and Azure Data Factory.\\n\\nIn short, without proper data ingestion, our analytics systems would be blind. It's the first and most crucial step in turning raw data into meaningful insights.\\n\\nThank you!\\n\\n\")]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"speech.txt\")\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ee8c989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 214, which is longer than the specified 100\n",
      "Created a chunk of size 358, which is longer than the specified 100\n",
      "Created a chunk of size 417, which is longer than the specified 100\n",
      "Created a chunk of size 165, which is longer than the specified 100\n",
      "Created a chunk of size 161, which is longer than the specified 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='Good morning everyone,'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='Today, I want to talk about a fundamental yet powerful concept in the data world — Data Ingestion.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='Data ingestion is the process of collecting and bringing data from various sources into a centralized system, like a data warehouse, data lake, or a database, where it can be further processed, analyzed, or stored.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='In today’s digital era, businesses collect data from many sources — mobile apps, websites, IoT devices, social media, and more. But having data in different places is not helpful unless we can bring it all together. That’s exactly what data ingestion does. It acts like a bridge — gathering raw data and transporting it into a system where it becomes usable.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='There are two major types of data ingestion: batch and real-time. In batch ingestion, data is collected and loaded at scheduled intervals — like every hour or once a day. This is great for systems that don’t need instant updates. On the other hand, real-time ingestion captures and loads data continuously, almost instantly — perfect for applications like fraud detection, live analytics, or monitoring smart devices.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='Many modern tools help with data ingestion — such as Apache Kafka for streaming, Apache NiFi for data flows, and cloud services like AWS Glue and Azure Data Factory.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content=\"In short, without proper data ingestion, our analytics systems would be blind. It's the first and most crucial step in turning raw data into meaningful insights.\"),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='Thank you!')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(separator=\"\\n\\n\" , chunk_size = 100 , chunk_overlap = 20) \n",
    "text_splitter.split_documents(docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809ae138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
